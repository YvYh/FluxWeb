{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YvYh/FluxWeb/blob/main/Model_Controverses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7JxozYqb4u"
      },
      "source": [
        "# **BQ**: Get/Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoWR0fEEVc2j"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "json_path = 'poc-bigdata.json'\n",
        "bigquery_client = bigquery.Client.from_service_account_json(json_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mxZ0VONVJ8y"
      },
      "source": [
        "def get_bq_data(query):\n",
        "  query_job = bigquery_client.query(query)\n",
        "  rows = query_job.result()\n",
        "  data = rows.to_dataframe()\n",
        "  return data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14I5mpYIVr4X"
      },
      "source": [
        "def bq_load_df(name, df):\n",
        "    dataset_ref = bigquery_client.dataset('FluxWeb_Prediction')\n",
        "    table_ref = dataset_ref.table(name)\n",
        "    \n",
        "    \n",
        "    job_config = bigquery.LoadJobConfig()\n",
        "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
        "    if name == 'Controverses_bert':\n",
        "      job_config.schema = get_bigquery_schema()\n",
        "    else:\n",
        "      job_config.autodetect=True\n",
        " \n",
        "    load_job = bigquery_client.load_table_from_dataframe(\n",
        "        df,\n",
        "        table_ref,\n",
        "        job_config=job_config)\n",
        " \n",
        "    assert load_job.job_type == 'load'\n",
        " \n",
        "    load_job.result()  # Waits for table load to complete.\n",
        " \n",
        "    assert load_job.state == 'DONE'\n",
        "    print('table {} load {} data.'.format(name, len(df)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoR75MPiUVvk"
      },
      "source": [
        "# Bert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urxDCSIZU1yR",
        "outputId": "2edf3603-0f15-444f-b3ea-8b1171f28627"
      },
      "source": [
        "!pip install -q tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4MB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 47.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 41.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 96kB/s \n",
            "\u001b[K     |████████████████████████████████| 706kB 40.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 38.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 34.7MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "nJkb4TJTRHK5",
        "outputId": "1589f895-9a2f-40cb-ab7c-db634178b912"
      },
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piS_D-NRU2ge"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs_lyCiqU8GI"
      },
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3'\n",
        " \n",
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POyL8MVnU_PN"
      },
      "source": [
        "def bert_vectorize(text_test):\n",
        "    \n",
        "    text_preprocessed = bert_preprocess_model([text_test])\n",
        "    bert_results = bert_model(text_preprocessed)\n",
        "    vect = bert_results[\"pooled_output\"][0,:]\n",
        "    return vect.numpy()\n",
        "    #return bert_vectorize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTkAdjV2V-B-"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "import time\n",
        " \n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "AQedb7ZgVPRD",
        "outputId": "a4925439-ab7f-4249-cc76-496e19b39a12"
      },
      "source": [
        "q_news = \"\"\"SELECT distinct id_news,News, NumControverse \n",
        "FROM `poc-bigdata.FluxWeb_Prediction.News_test` \n",
        "Order by id_news desc\n",
        "\"\"\"\n",
        "news = get_bq_data(q_news)\n",
        "news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_news</th>\n",
              "      <th>News</th>\n",
              "      <th>NumControverse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N957069</td>\n",
              "      <td>Carrefour mise un milliard sur les anciens act...</td>\n",
              "      <td>3265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N957069</td>\n",
              "      <td>Carrefour mise un milliard sur les anciens act...</td>\n",
              "      <td>1689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N957069</td>\n",
              "      <td>Carrefour mise un milliard sur les anciens act...</td>\n",
              "      <td>3006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N957069</td>\n",
              "      <td>Carrefour mise un milliard sur les anciens act...</td>\n",
              "      <td>3412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N957069</td>\n",
              "      <td>Carrefour mise un milliard sur les anciens act...</td>\n",
              "      <td>2722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_news                                               News  NumControverse\n",
              "0  N957069  Carrefour mise un milliard sur les anciens act...            3265\n",
              "1  N957069  Carrefour mise un milliard sur les anciens act...            1689\n",
              "2  N957069  Carrefour mise un milliard sur les anciens act...            3006\n",
              "3  N957069  Carrefour mise un milliard sur les anciens act...            3412\n",
              "4  N957069  Carrefour mise un milliard sur les anciens act...            2722"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEVTek1lQ2mz",
        "outputId": "dfdfd245-b4c9-464d-bc3b-d56fb47b7661"
      },
      "source": [
        "import pickle\n",
        "svd=pickle.load(open('svd120.pickle', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator TruncatedSVD from version 0.23.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DZgfKceVPoX",
        "outputId": "755a870a-e7b4-4db1-d118-5b62a2c30e23"
      },
      "source": [
        "cosine_similarity(svd.transform([news_bert]),svd.transform(controverses.vect_c.to_list()))[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98004867, 0.8753628 , 0.90957654])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qxKpNNzWHNR"
      },
      "source": [
        "nb = len(news.id_news.unique())\n",
        "print(str(nb))\n",
        "i = 0\n",
        "out = display(progress(0, nb), display_id=True)\n",
        "for idn in news.id_news.unique():\n",
        "\n",
        "  news_text = news[news['id_news']==idn]['News'].iloc[0]\n",
        "  news_bert = bert_vectorize(news_text)\n",
        "  nums = news[news['id_news']==idn]['NumControverse']\n",
        "  #print(i/nb)\n",
        "\n",
        "  result = pd.DataFrame()\n",
        "  for idc in nums:\n",
        "    q_vectC = \"SELECT NumControverse,Poids,[Embed_\"+\", Embed_\".join([str(x) for x in range(768)])+\"] vect_c FROM `poc-bigdata.FluxWeb_Prediction.Controverses_bert` WHERE NumControverse={}\".format(str(idc))\n",
        "    controverses = get_bq_data(q_vectC)\n",
        "    cos = cosine_similarity([news_bert],controverses.vect_c.to_list())[0]\n",
        "    cos120 = cosine_similarity(svd.transform([news_bert]),svd.transform(controverses.vect_c.to_list()))[0]\n",
        "    s = controverses.Poids.sum()\n",
        "    poids = [x/s for x in controverses.Poids]\n",
        "    result = result.append({'id_news':idn,\n",
        "                            'numControverse':idc,\n",
        "                            'bert_score':sum(cos*poids),\n",
        "                            'bert_svd120_score':sum(cos120*poids)}\n",
        "                            ,ignore_index=True)\n",
        "  bq_load_df_in_gcs('Controverse_News_Score', result)\n",
        "  out.update(progress(i, nb))\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBKdP9-8pfuW"
      },
      "source": [
        "# **TensorFlow**:  TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTVq5YN56-Fc"
      },
      "source": [
        "### Get Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nvtPr9q7tnu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Ln9vXYpkRX"
      },
      "source": [
        "q = \"\"\"SELECT DISTINCT NumControverse as label, Titre as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "UNION ALL \n",
        "SELECT DISTINCT NumControverse as label, Commentaire as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "WHERE Commentaire is not null and length(Commentaire)>5\n",
        "UNION ALL \n",
        "SELECT DISTINCT NumControverse as label, Informations as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "WHERE Informations is not null\n",
        "\"\"\"\n",
        "controverses = get_bq_data(q)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqtPfh_EpdkM"
      },
      "source": [
        "#controverses['Text_clean']=controverses.Text.apply(text_preprossing)\n",
        "controverses = controverses[['label','Text']]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "MSdOrlfrz95b",
        "outputId": "f3646c86-7aac-445f-80a1-36015501c19b"
      },
      "source": [
        "print(len(controverses))\n",
        "print(len(controverses.label.unique()))\n",
        "controverses.head()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3751\n",
            "1408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2866</td>\n",
              "      <td>Révélation d'un scandale comptable survenu en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389</td>\n",
              "      <td>EPR de Flamanville: malfaçons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2543</td>\n",
              "      <td>Condamnation suite à des déversements dans des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3506</td>\n",
              "      <td>Poursuites aux Etats-Unis en lien avec les émi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3016</td>\n",
              "      <td>Incendie dans une usine de Lubrizol à Rouen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               Text\n",
              "0   2866  Révélation d'un scandale comptable survenu en ...\n",
              "1    389                      EPR de Flamanville: malfaçons\n",
              "2   2543  Condamnation suite à des déversements dans des...\n",
              "3   3506  Poursuites aux Etats-Unis en lien avec les émi...\n",
              "4   3016        Incendie dans une usine de Lubrizol à Rouen"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6AlgtWqsD7q"
      },
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download fr_core_news_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBzAA6MZ3Y9I"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"fr_core_news_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp-fCZ9YrIgf"
      },
      "source": [
        "def text_preprossing(text):\n",
        "    tokens = nlp(text)\n",
        "    clean = []\n",
        "    for token in tokens:\n",
        "        if not any([token.is_digit, token.is_punct, token.is_currency,\n",
        "               token.like_url, token.like_num, token.like_email,\n",
        "               token.is_stop]):\n",
        "            clean += [token.lemma_]\n",
        "    #return tf.strings.join(clean, separator=' ')\n",
        "    return ' '.join(clean)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2CymuS5CteF",
        "outputId": "65464648-1aed-4cbd-9fa7-3323a61ae02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "data = pd.DataFrame()\n",
        "data['label'] = controverses.label\n",
        "data['Text'] = controverses.Text.apply(text_preprossing)\n",
        "data.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2866</td>\n",
              "      <td>révélation scandale comptable survenir impliqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389</td>\n",
              "      <td>epr Flamanville malfaçon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2543</td>\n",
              "      <td>condamnation suite déversement rivière</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3506</td>\n",
              "      <td>poursuite Etats-Unis lien émission no niveau c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3016</td>\n",
              "      <td>incendie usine Lubrizol Rouen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               Text\n",
              "0   2866  révélation scandale comptable survenir impliqu...\n",
              "1    389                           epr Flamanville malfaçon\n",
              "2   2543             condamnation suite déversement rivière\n",
              "3   3506  poursuite Etats-Unis lien émission no niveau c...\n",
              "4   3016                      incendie usine Lubrizol Rouen"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLFEyswQuZm4",
        "outputId": "aff0525f-3ebb-4c7d-ecb1-40c9c9068e0f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400 train examples\n",
            "600 validation examples\n",
            "751 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieVNljkp5rGf",
        "outputId": "a7afb759-27bd-4457-9b05-d028f42d058e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "val.head()"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1212</th>\n",
              "      <td>69</td>\n",
              "      <td>procédure cours cadre fait avérer corruption</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3551</th>\n",
              "      <td>3178</td>\n",
              "      <td>ancien avocat filiale conglomérat Danaher Corp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1040</th>\n",
              "      <td>3370</td>\n",
              "      <td>reprise opération Carnival Etats-Unis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2858</th>\n",
              "      <td>2604</td>\n",
              "      <td>syndicat approuver octobre accord proposer pdg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>1407</td>\n",
              "      <td>rapport critique institution financier finance...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label                                               Text\n",
              "1212     69       procédure cours cadre fait avérer corruption\n",
              "3551   3178  ancien avocat filiale conglomérat Danaher Corp...\n",
              "1040   3370              reprise opération Carnival Etats-Unis\n",
              "2858   2604  syndicat approuver octobre accord proposer pdg...\n",
              "69     1407  rapport critique institution financier finance..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiovEVoevuJu"
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  #dataframe = dataframe.copy()\n",
        "  #labels = dataframe.pop('label')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dataframe.Text.values, dataframe.label.values))\n",
        "  #ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Sb6DDzwxBb",
        "outputId": "de70d245-b41a-4b36-8d42-af986f47855a"
      },
      "source": [
        "batch_size = 32 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
        "train_ds"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bThDbEb-6rRf",
        "outputId": "a877d3e5-ba9c-4d0f-a535-5b0f27f10a5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(5):\n",
        "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3319 b'enqu\\xc3\\xaate conduire ICIJ m\\xc3\\xa9dia montre grand banque poreux blanchiment argent base suspiciou activity report SAR transmettre banque autorit\\xc3\\xa9 lutte antiblanchiment am\\xc3\\xa9ricain fincen rapport ultraconfidentiels repr\\xc3\\xa9senter total mds$ transaction suspect r\\xc3\\xa9aliser montrer banque circuler passivement travers compte bancaire personne soci\\xc3\\xa9t\\xc3\\xa9 identifier argent susceptible relever blanchiment aucun banque solliciter souhaiter r\\xc3\\xa9agir fincen proposer septembre vaste r\\xc3\\xa9forme cens\\xc3\\xa9 am\\xc3\\xa9liorer efficacit\\xc3\\xa9 lutte anti-blanchiment renforcer obligation d\\xc3\\xa9claration banque   '\n",
            "3460 b'critique politique \\xc3\\xa9conomique chinois fondateur cons\\xc3\\xa9quence'\n",
            "1330 b'ong n\\xc3\\xa9erlandais milieudefensie enqu\\xc3\\xaater fournisseur huile palme Neste neste acheter mt distillat acide gras palme pfad d\\xc3\\xa9chet production huile palme principalement malaisie indon\\xc3\\xa9sie ong accuse Neste destruction for\\xc3\\xaat tropical achat cours dernier mois fournisseur impliquer incendie feu observer conflit foncier pot-de-vin violation droit travail exemple First Resources Ltd accuser d\\xc3\\xa9fricher hectare for\\xc3\\xaat tropical feu conflit foncier communaut\\xc3\\xa9 local   Golden Agri Resources incendie \\xc3\\xaatre d\\xc3\\xa9nombrer filiale Golden Veroleum Liberia utiliser force arm\\xc3\\xa9e extorquer terrain aupr\\xc3\\xa8s population local plaindre'\n",
            "2485 b'Soci\\xc3\\xa9t\\xc3\\xa9 energie eau Gabon seeg filiale groupe Veolia d\\xc3\\xa9poser mars demande conciliation international demande suite r\\xc3\\xa9quisition actif personnel r\\xc3\\xa9siliation brutal concession service public production transport distribution eau potable \\xc3\\xa9nergie \\xc3\\xa9lectrique r\\xc3\\xa9publique Gabon f\\xc3\\xa9vrier gouvernement invoquer d\\xc3\\xa9gradation qualit\\xc3\\xa9 service rendre usager effort financier consentir etat non suivre effet escompter plainte r\\xc3\\xa9current utilisateur seeg estime r\\xc3\\xa9siliation r\\xc3\\xa9quisition ill\\xc3\\xa9gal causer grave pr\\xc3\\xa9judice'\n",
            "2772 b'malaisie annoncer vendredi Goldman Sachs accepter accord mds$ Mds clore scandale lier fonds souverain 1MDB banque affaire am\\xc3\\xa9ricain verser malaisie mds$ garantir md$ actif lier obligation fonds 1MDB pr\\xc3\\xa9ciser minist\\xc3\\xa8re malaisien finance communiqu\\xc3\\xa9 parquet malaisien engager d\\xc3\\xa9cembre poursuite judiciaire contre unit\\xc3\\xa9 Goldman Sachs accusation tromperie encontre investisseur \\xc3\\xa9mission obligataire organiser banque profit fonds 1mdb total mds$.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvf5tfl262Fl"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYhU3yhg7ysF"
      },
      "source": [
        "-------  \n",
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yf38V0Spgg3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqSEtyDksvBK"
      },
      "source": [
        "vocab_size = 10000\n",
        "sequence_length = 600\n",
        "\n",
        "# Use the text vectorization layer to normalize, split, and map strings to\n",
        "# integers. Set output_sequence_length length to pad all samples to same length.\n",
        "vectorize_layer = TextVectorization(\n",
        "    #standardize= text_preprossing,\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='tf-idf',\n",
        "    #output_sequence_length=sequence_length\n",
        "    )"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGjzxZGsBxBM"
      },
      "source": [
        "text_list = train.Text.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0k6GOBN50x8"
      },
      "source": [
        "vectorize_layer.adapt(text_list)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i4oz_7nInN2"
      },
      "source": [
        "vectorize_layer.get_vocabulary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoTERsbu3sRX"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBFZEV8YHyAA"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "embedding_dim=1000\n",
        "\n",
        "model = Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dense(1)\n",
        "])"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUf31CwRH7Ng"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaKzMiSM6k8C",
        "outputId": "06b87fa6-c7b0-4790-fda5-e89da133fc6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_ds, \n",
        "          epochs=40, \n",
        "          validation_data=val_ds)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 3s 26ms/step - loss: -779.2183 - accuracy: 0.0000e+00 - val_loss: -1786.3885 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 2s 24ms/step - loss: -4096.7046 - accuracy: 0.0000e+00 - val_loss: -7218.8159 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 2s 24ms/step - loss: -13170.0039 - accuracy: 0.0000e+00 - val_loss: -20210.8047 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 2s 23ms/step - loss: -31861.1738 - accuracy: 0.0000e+00 - val_loss: -44427.7812 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 2s 23ms/step - loss: -63834.3125 - accuracy: 0.0000e+00 - val_loss: -83342.9688 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 2s 24ms/step - loss: -112532.9219 - accuracy: 0.0000e+00 - val_loss: -140196.9688 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 2s 24ms/step - loss: -181148.9375 - accuracy: 0.0000e+00 - val_loss: -217976.3750 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 2s 24ms/step - loss: -272621.8750 - accuracy: 0.0000e+00 - val_loss: -319431.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 2s 23ms/step - loss: -389657.6562 - accuracy: 0.0000e+00 - val_loss: -447080.0625 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 2s 23ms/step - loss: -534746.1875 - accuracy: 0.0000e+00 - val_loss: -603253.3125 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5a0eef3910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeSaSkfTILKT",
        "outputId": "3045297b-fa41-4e8a-a147-5e98e1bf3bae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization_5 (TextVe (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 10000, 16)         160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u88jdipb6nRU",
        "outputId": "8d164790-80f1-4306-a038-bdf21a046521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 9ms/step - loss: -602432.0625 - accuracy: 0.0000e+00\n",
            "Accuracy 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eURBDR2KKORo"
      },
      "source": [
        "#### tfidf model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRq0QLFCLAWo"
      },
      "source": [
        "def text_preprossing2(text):\n",
        "    tokens = nlp(text)\n",
        "    clean = []\n",
        "    for token in tokens:\n",
        "        if not any([token.is_digit, token.is_punct, token.is_currency,\n",
        "               token.like_url, token.like_num, token.like_email,\n",
        "               token.is_stop]):\n",
        "            clean += [token.lemma_]\n",
        "    return tf.strings.join(clean, separator=' ')\n",
        "    #return ' '.join(clean)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nyk7GW7K_uO"
      },
      "source": [
        "vectorize_layer2 = TextVectorization(\n",
        "    #standardize= text_preprossing,\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='tf-idf',\n",
        "    #output_sequence_length=sequence_length\n",
        "    )"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li6SLYUjLJGN"
      },
      "source": [
        "vectorize_layer2.adapt(data.Text.values.tolist())"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSPsmJTnKNig",
        "outputId": "78b1030b-a8d2-4d05-e17d-7cd6dc631a4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf = tf.keras.models.Sequential()\n",
        "tfidf.add(tf.keras.Input(shape=(1,),dtype=tf.string))\n",
        "tfidf.add(vectorize_layer2)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iECWOpVNMzh",
        "outputId": "13c99f4b-c17a-437e-d9ea-fb497efc14d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        }
      },
      "source": [
        "tfidf.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "tfidf.fit(train.Text.values.tolist(), \n",
        "          epochs=40, \n",
        "          validation_data=val.Text.values.tolist())"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-154-11702403d63f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m tfidf.fit(train.Text.values.tolist(), \n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_data=val.Text.values.tolist())\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:800 train_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:439 update_state\n        self.build(y_pred, y_true)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:362 build\n        self._metrics, y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1378 map_structure_up_to\n        **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1473 map_structure_with_tuple_paths_up_to\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1473 <listcomp>\n        func(*args, **kwargs) for args in zip(flat_path_gen, *flat_value_gen)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py:1376 <lambda>\n        lambda _, *values: func(*values),  # Discards the path arg.\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:485 _get_metric_objects\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:485 <listcomp>\n        return [self._get_metric_object(m, y_t, y_p) for m in metrics]\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:506 _get_metric_object\n        y_t_rank = len(y_t.shape.as_list())\n\n    AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Wm1OCmL0JU",
        "outputId": "5ac74213-8bd2-44fd-e2c4-bdc9871b6ce6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test.Text.values[0])\n",
        "tfidf.predict([test.Text.values[0]])"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "US Equal Employment Opportunity commission EEOC intenter action justice tribunal fédéral NY contre Walmart enfreindre loi fédéral laisser employé masculin harceler sexuellement collègue travail prendre mesure cesse lieu mettre fin harcèlement Walmart demander employé harceler défendre contraindre salarié démissionner agence fédéral affirme walmart recevoir plainte sujet comportement harcelant homme partir entreprise prendre mesure efficace faire cesser harcèlement eeoc réclame arriéré salaire dommage intérêt compensatoire dommage intérêt punitif employé concerner mesure redressement prévenir potentiel cas harcèlement sexuel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.586464, 0.      , 0.      , ..., 0.      , 0.      , 0.      ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUh5-B936p9q",
        "outputId": "49c525bf-1800-402c-ac0a-4a93dfbb7efd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfidf.save('tf_idf_model')\n",
        "#reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: tf_idf_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hCijeiB6zP7"
      },
      "source": [
        "news =''\n",
        "\n",
        "input_dict = {'Text': tf.convert_to_tensor([news])}\n",
        "predictions = reloaded_model.predict(input_dict)\n",
        "prob = tf.nn.sigmoid(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This particular pet had a %.1f percent probability \"\n",
        "    \"of getting adopted.\" % (100 * prob)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}