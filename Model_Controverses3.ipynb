{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YvYh/FluxWeb/blob/main/Model_Controverses3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7JxozYqb4u"
      },
      "source": [
        "# **BQ**: Get/Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoWR0fEEVc2j"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "json_path = 'poc-bigdata.json'\n",
        "bigquery_client = bigquery.Client.from_service_account_json(json_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mxZ0VONVJ8y"
      },
      "source": [
        "def get_bq_data(query):\n",
        "  query_job = bigquery_client.query(query)\n",
        "  rows = query_job.result()\n",
        "  data = rows.to_dataframe()\n",
        "  return data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14I5mpYIVr4X"
      },
      "source": [
        "def bq_load_df(name, df):\n",
        "    dataset_ref = bigquery_client.dataset('FluxWeb_Prediction')\n",
        "    table_ref = dataset_ref.table(name)\n",
        "    \n",
        "    \n",
        "    job_config = bigquery.LoadJobConfig()\n",
        "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
        "    if name == 'Controverses_bert':\n",
        "      job_config.schema = get_bigquery_schema()\n",
        "    else:\n",
        "      job_config.autodetect=True\n",
        " \n",
        "    load_job = bigquery_client.load_table_from_dataframe(\n",
        "        df,\n",
        "        table_ref,\n",
        "        job_config=job_config)\n",
        " \n",
        "    assert load_job.job_type == 'load'\n",
        " \n",
        "    load_job.result()  # Waits for table load to complete.\n",
        " \n",
        "    assert load_job.state == 'DONE'\n",
        "    print('table {} load {} data.'.format(name, len(df)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBKdP9-8pfuW"
      },
      "source": [
        "# **TensorFlow**:  TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTVq5YN56-Fc"
      },
      "source": [
        "### Get Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nvtPr9q7tnu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Ln9vXYpkRX"
      },
      "source": [
        " \"\"\"SELECT DISTINCT NumControverse as label, Titre as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "UNION ALL \n",
        "SELECT DISTINCT NumControverse as label, Commentaire as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "WHERE Commentaire is not null and length(Commentaire)>5\n",
        "UNION ALL \n",
        "SELECT DISTINCT NumControverse as label, Informations as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "WHERE Informations is not null\n",
        "\"\"\"\n",
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset`\"\n",
        "controverses = get_bq_data(q)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqtPfh_EpdkM"
      },
      "source": [
        "#controverses['Text_clean']=controverses.Text.apply(text_preprossing)\n",
        "controverses = controverses[['label','Text']]"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "MSdOrlfrz95b",
        "outputId": "38d8eb49-1c7f-4425-d166-1ebe24418360"
      },
      "source": [
        "print(len(controverses))\n",
        "print(len(controverses.label.unique()))\n",
        "controverses.head()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11537\n",
            "1408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2866</td>\n",
              "      <td>Révélation d'un scandale comptable survenu en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389</td>\n",
              "      <td>EPR de Flamanville: malfaçons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2543</td>\n",
              "      <td>Condamnation suite à des déversements dans des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3506</td>\n",
              "      <td>Poursuites aux Etats-Unis en lien avec les émi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3016</td>\n",
              "      <td>Incendie dans une usine de Lubrizol à Rouen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               Text\n",
              "0   2866  Révélation d'un scandale comptable survenu en ...\n",
              "1    389                      EPR de Flamanville: malfaçons\n",
              "2   2543  Condamnation suite à des déversements dans des...\n",
              "3   3506  Poursuites aux Etats-Unis en lien avec les émi...\n",
              "4   3016        Incendie dans une usine de Lubrizol à Rouen"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCNXhJFWW7q7",
        "outputId": "bbd67114-9b73-46a1-b17c-7e1aab27e3ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "controverses['label'] = controverses['label'].astype('str')\n",
        "controverses.label.dtypes"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xxz936WnQPs",
        "outputId": "f7b1ad0b-ecdc-4ed0-884e-2fce551b7e20"
      },
      "source": [
        "controverses.label.sort_values().unique()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1023', '1082', '1092', ..., '94', '952', '955'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T41MC8evoEWV"
      },
      "source": [
        "#label_index = {k: v for v, k in enumerate(controverses.label.sort_values().unique())}\n",
        "#controverses.label = controverses.label.map(lambda x: label_index.get(x))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYLWAp_aqyX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7747d9-20b2-41aa-bac2-b7419c852f52"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#train, test = train_test_split(controverses, test_size=0.04)\n",
        "train, val = train_test_split(controverses, test_size=0.1)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "#print(len(test), 'test examples')"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10383 train examples\n",
            "1154 validation examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1zlcJ_AXpxN",
        "outputId": "0cab0a47-0224-45c9-ca2e-0afab703a336",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset_test`\"\n",
        "test = get_bq_data(q)\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1254 test examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQTi0l4eX33G"
      },
      "source": [
        "test['label'] = test['label'].astype('str')"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ5e1rs7tvpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8a77b3-d959-4eee-a332-966bfbfeb766"
      },
      "source": [
        "train.Text"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6292     La firme a indiqué qu'elle décidera dans les p...\n",
              "253      Les émetteurs de titres restaurant lourdement ...\n",
              "180      La gamme AmazonBasics poserait des risques aux...\n",
              "9525     Les deux parties se sont précédemment déjà réu...\n",
              "1004     L'autorité allemande de la concurrence inflige...\n",
              "                               ...                        \n",
              "9403     Orange anciennement France Télécom, a été cond...\n",
              "8592     Les tribus indigènes et les écologistes ont cr...\n",
              "11482    La Commission européenne, par l'intermédiaire ...\n",
              "1129     Endesa accusé d'avoir provoqué la mort de 255 ...\n",
              "9940      La Swedbank et SEB font déjà l'objet d'une en...\n",
              "Name: Text, Length: 10383, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPJ119Tpp_0"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNSuVrS9rD5L"
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('label')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dataframe.Text, labels.values))\n",
        "  #ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNdFIf0Asv-Z"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 32\n",
        "raw_train_ds = df_to_dataset(train)\n",
        "raw_test_ds = df_to_dataset(test)\n",
        "raw_val_ds= df_to_dataset(val)\n",
        "raw_train_ds = raw_train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "raw_test_ds = raw_test_ds.prefetch(tf.data.AUTOTUNE)\n",
        "raw_val_ds = raw_val_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkpYs1_6s6rO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98792b3-df6a-48a5-c2b0-904bafb0669c"
      },
      "source": [
        "for example, label in raw_train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print('texts: ', example.numpy()[i])\n",
        "    print('labels: ', label.numpy()[i])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  b\"La banque dispose d'un d\\xc3\\xa9lai de vingt jours pour pr\\xc3\\xa9senter un plan de fermeture de sa succursale\"\n",
            "labels:  b'2348'\n",
            "texts:  b\"On ne sait pas pour le moment si d'autres pays sont concern\\xc3\\xa9s mais il est fort possible que ce soit le cas\"\n",
            "labels:  b'2572'\n",
            "texts:  b\"Un membre d'Animal Equality a travaill\\xc3\\xa9 de fa\\xc3\\xa7on dissimul\\xc3\\xa9e pour Moy Park qui d\\xc3\\xa9tient un tiers du march\\xc3\\xa9 de la volaille au Royaume-Uni et vend aux grandes surfaces comme Tesco et Ocado\"\n",
            "labels:  b'2942'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZPywzqc2sof"
      },
      "source": [
        "### Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6AlgtWqsD7q"
      },
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download fr_core_news_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBzAA6MZ3Y9I"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"fr_core_news_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp-fCZ9YrIgf"
      },
      "source": [
        "def text_preprossing(text):\n",
        "    tokens = nlp(text)\n",
        "    clean = []\n",
        "    for token in tokens:\n",
        "        if not any([token.is_digit, token.is_punct, token.is_currency,\n",
        "               token.like_url, token.like_num, token.like_email,\n",
        "               token.is_stop]):\n",
        "            clean += [token.lemma_]\n",
        "    return tf.strings.join(clean, separator=' ')\n",
        "    #return ' '.join(clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYhU3yhg7ysF"
      },
      "source": [
        "-------  \n",
        "### Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yf38V0Spgg3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGjzxZGsBxBM"
      },
      "source": [
        "text_list = train.Text.values.tolist()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0k6GOBN50x8",
        "outputId": "a10e73ae-4f16-43b3-924a-bf0e361080b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "vectorize_layer.adapt(text_list)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-5e390fc27731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorize_layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i4oz_7nInN2"
      },
      "source": [
        "vectorize_layer.get_vocabulary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoTERsbu3sRX"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBFZEV8YHyAA"
      },
      "source": [
        "\n",
        "embedding_dim=1000\n",
        "\n",
        "model = Sequential([\n",
        "  vectorize_layer,\n",
        "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
        "  GlobalAveragePooling1D(),\n",
        "  Dense(16, activation='relu'),\n",
        "  Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUf31CwRH7Ng"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaKzMiSM6k8C"
      },
      "source": [
        "model.fit(train_ds, \n",
        "          epochs=40, \n",
        "          validation_data=val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeSaSkfTILKT"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u88jdipb6nRU"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eURBDR2KKORo"
      },
      "source": [
        "#### tfidf model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRq0QLFCLAWo"
      },
      "source": [
        "def text_preprossing2(text):\n",
        "    tokens = nlp(text)\n",
        "    clean = []\n",
        "    for token in tokens:\n",
        "        if not any([token.is_digit, token.is_punct, token.is_currency,\n",
        "               token.like_url, token.like_num, token.like_email,\n",
        "               token.is_stop]):\n",
        "            clean += [token.lemma_]\n",
        "    return tf.strings.join(clean, separator=' ')\n",
        "    #return ' '.join(clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nyk7GW7K_uO"
      },
      "source": [
        "vectorize_layer2 = TextVectorization(\n",
        "    #standardize= text_preprossing,\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='tf-idf',\n",
        "    #output_sequence_length=sequence_length\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li6SLYUjLJGN"
      },
      "source": [
        "vectorize_layer2.adapt(data.Text.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSPsmJTnKNig"
      },
      "source": [
        "tfidf = tf.keras.models.Sequential()\n",
        "tfidf.add(tf.keras.Input(shape=(1,),dtype=tf.string))\n",
        "tfidf.add(vectorize_layer2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iECWOpVNMzh"
      },
      "source": [
        "tfidf.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "tfidf.fit(train.Text.values.tolist(), \n",
        "          epochs=40, \n",
        "          validation_data=val.Text.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Wm1OCmL0JU"
      },
      "source": [
        "print(test.Text.values[0])\n",
        "tfidf.predict([test.Text.values[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUh5-B936p9q"
      },
      "source": [
        "tfidf.save('tf_idf_model')\n",
        "#reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hCijeiB6zP7"
      },
      "source": [
        "news =''\n",
        "\n",
        "input_dict = {'Text': tf.convert_to_tensor([news])}\n",
        "predictions = reloaded_model.predict(input_dict)\n",
        "prob = tf.nn.sigmoid(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This particular pet had a %.1f percent probability \"\n",
        "    \"of getting adopted.\" % (100 * prob)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmOFNNwGVtct"
      },
      "source": [
        "### Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR6p1S-8VsfN"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woMyx2sCZaVb",
        "outputId": "cb6b8e1b-1b14-4520-8bff-86f423f1cf4f"
      },
      "source": [
        "train_text = train_ds.map(lambda text,label: text)\n",
        "train_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: (None, 1), types: tf.string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncars-ZOV33O"
      },
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(10):\n",
        "    print(\"Text: \", text_batch.numpy()[i])\n",
        "    print(\"Label:\", label_batch.numpy()[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrQD9fYuWCKM"
      },
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download fr_core_news_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wji5qwMXdmN"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"fr_core_news_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv2kG-7mXgAt"
      },
      "source": [
        "def get_text(t: tf.Tensor):\n",
        "  return t.numpy().decode('utf-8')\n",
        "def text_preprossing(text: np.ndarray):\n",
        "  result = []\n",
        "  for t in text:\n",
        "    tokens = nlp(t.decode('utf-8'))\n",
        "    clean = []\n",
        "    for token in tokens:\n",
        "        if not any([token.is_digit, token.is_punct, token.is_currency,\n",
        "              token.like_url, token.like_num, token.like_email,\n",
        "              token.is_stop]):\n",
        "            clean += [token.lemma_]\n",
        "    #result = result+ [[tf.strings.join(clean, separator=' ')]]\n",
        "    result = result+ [[' '.join(clean)]]\n",
        "    #return ' '.join(clean)\n",
        "    print(result)\n",
        "  return tf.constant(result)\n",
        "def clean_text(t: tf.Tensor):\n",
        "  return tf.py_function(func=text_preprossing, inp=[t], Tout=tf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_X25xR7hzqN"
      },
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEb96u4feOTz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fd5376eb-2a0c-40cb-e525-efbe36d44611"
      },
      "source": [
        "test_text = test_ds.map(lambda text,label: text)\n",
        "test = next(iter(test_text))\n",
        "print(test)\n",
        "clean_text(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[b\"Ces enqu\\xc3\\xaates portaient sur l'embauche d'enfants de personnalit\\xc3\\xa9s chinoises et visaient plusieurs banques, soup\\xc3\\xa7onn\\xc3\\xa9es de les avoir recrut\\xc3\\xa9s, dans l'espoir d'obtenir des contrats\"]\n",
            " [b\"Apr\\xc3\\xa8s des \\xc3\\xa9meutes en 2016, d'autres violations ont eu lieu dans ce centre mais dans d'autres \\xc3\\xa9galement\"]\n",
            " [b'Quatre groupes indig\\xc3\\xa8nes ont demand\\xc3\\xa9 \\xc3\\xa0 Frontera de nettoyer les dommages environnementaux li\\xc3\\xa9s aux d\\xc3\\xa9versements de p\\xc3\\xa9trole du Lot 192, le plus grand puits de p\\xc3\\xa9trole du P\\xc3\\xa9rou']\n",
            " [b\"Edison a vers\\xc3\\xa9 500 $ par habitant et une enqu\\xc3\\xaate est en cours pour d\\xc3\\xa9terminer les causes de l'accident\"]\n",
            " [b\"La CFTC (US Commodity Futures Trading Commission) avait d\\xc3\\xa9pos\\xc3\\xa9 plainte contre Kraft Foods et Mondelez en Illinois en avril 2015, all\\xc3\\xa9guant que les soci\\xc3\\xa9t\\xc3\\xa9s avaient manipul\\xc3\\xa9 les prix du bl\\xc3\\xa9 (options) et du bl\\xc3\\xa9 (futures) \\xc3\\xa0 partir de fin 2011, r\\xc3\\xa9alisant des b\\xc3\\xa9n\\xc3\\xa9fices d'environ 5,4 M USD\"]\n",
            " [b'La banque encourt une amende 5Mds?, correspondant \\xc3\\xa0 la moiti\\xc3\\xa9 des montants sur lesquels portent les op\\xc3\\xa9rations pr\\xc3\\xa9sum\\xc3\\xa9es frauduleuses.']\n",
            " [b'Les maisons, champs, ressources en eau et les sites culturels et religieux des r\\xc3\\xa9sidents locaux auraient \\xc3\\xa9t\\xc3\\xa9 d\\xc3\\xa9truits']\n",
            " [b\"Dans un rapport publi\\xc3\\xa9 mi-septembre, l'ONG Solidar Suisse d\\xc3\\xa9taille les violations des droits de l'homme qu'elle a constat\\xc3\\xa9es dans deux plantations d'huile de palme fournissant, selon elle, Nestl\\xc3\\xa9 en Malaisie (Etat de Sabah sans que les plantations pr\\xc3\\xa9cises n'aient \\xc3\\xa9t\\xc3\\xa9 r\\xc3\\xa9v\\xc3\\xa9l\\xc3\\xa9es)\"]\n",
            " [b'Le CEO Don Katz semble vouloir changer cela en prenant des mesures et en appelant les collaborateurs \\xc3\\xa0 rapporter tout comportement inappropri\\xc3\\xa9']\n",
            " [b'Un nouveau jugement par une Cour sup\\xc3\\xa9rieure pourrait intervenir dans les 2 ans']\n",
            " [b'De plus, une enqu\\xc3\\xaate, toujours en cours, a \\xc3\\xa9t\\xc3\\xa9 ouverte en avril 2018 par les Forces arm\\xc3\\xa9es royales du Maroc']\n",
            " [b\"En 2018 Eni a affirm\\xc3\\xa9 devant le tribunal qu'il n'y a aucun lien entre la pollution d'origine industrielle et les cas de malformation n\\xc3\\xa9onatale\"]\n",
            " [b'Cette affaire continue de peser lourdement sur la r\\xc3\\xa9putation du groupe ainsi que sur son cours de bourse et ses b\\xc3\\xa9n\\xc3\\xa9fices']\n",
            " [b\"Le groupe L'Or\\xc3\\xa9al a annonc\\xc3\\xa9 qu'il allait verser un total de 320 millions d'euros au fisc fran\\xc3\\xa7ais pour \\xc2\\xab r\\xc3\\xa9gler un diff\\xc3\\xa9rend \\xc2\\xbb sur la base imposable de certaines de ses filiales dont Lanc\\xc3\\xb4me, concernant principalement l'imp\\xc3\\xb4t sur les soci\\xc3\\xa9t\\xc3\\xa9s r\\xc3\\xa9gl\\xc3\\xa9 entre 2014 et 2018\"]\n",
            " [b'Abus de position dominante \\xc3\\xa0 Taiwan: une amende largement r\\xc3\\xa9duite pour Qualcomm']\n",
            " [b\"Les deux directeurs (le Chief Content Officer et le Chief Revenue Officer) ont brusquement quitt\\xc3\\xa9 le groupe en plein milieu d'une enqu\\xc3\\xaate, qui fait suite \\xc3\\xa0 un questionnaire rempli par les collaborateurs d'Audible\"]\n",
            " [b\"L'UE a sanctionn\\xc3\\xa9 Qualcomm d'une amende de 242M? pour ses pratiques anticoncurrentielles\"]\n",
            " [b'La contamination avait \\xc3\\xa9t\\xc3\\xa9 d\\xc3\\xa9couverte pour la premi\\xc3\\xa8re fois en avril 2017, mais la communaut\\xc3\\xa9 en avait \\xc3\\xa9t\\xc3\\xa9 inform\\xc3\\xa9e en ao\\xc3\\xbbt 2017']\n",
            " [b'Le Dengvaxia a, par ailleurs, \\xc3\\xa9t\\xc3\\xa9 autoris\\xc3\\xa9 \\xc3\\xa0 la vente en Europe en d\\xc3\\xa9cembre 2018 pour des personnes ayant d\\xc3\\xa9j\\xc3\\xa0 \\xc3\\xa9t\\xc3\\xa9 infect\\xc3\\xa9es par le virus']\n",
            " [b\"Le groupe a accept\\xc3\\xa9 de collaborer au d\\xc3\\xa9but de l'enqu\\xc3\\xaate ce qui lui a permis de diminuer de 30% le montant de la p\\xc3\\xa9nalit\\xc3\\xa9 qu'elle risquait initialement de recevoir.\"]\n",
            " [b\"Le parquet fait \\xc3\\xa9tat du t\\xc3\\xa9moignage d'une personne qui aurait \\xc3\\xa9t\\xc3\\xa9 mise au courant de l'article du FT avant sa publication\"]\n",
            " [b\"Il aurait en effet identifi\\xc3\\xa9 365 comptes en Su\\xc3\\xa8de, au Danemark, en Finlande et en Norv\\xc3\\xa8ge sur lesquels auraient transit\\xc3\\xa9 175M$ afin de blanchir de l'argent sale en provenance de Russie entre 2007 et 2013\"]\n",
            " [b\"La BaFin a indiqu\\xc3\\xa9 enqu\\xc3\\xaater sur Grenke et d'\\xc3\\xa9ventuelles manipulations de march\\xc3\\xa9s autour de cette affaire\"]\n",
            " [b'Une nouvelle poursuite a \\xc3\\xa9t\\xc3\\xa9 intent\\xc3\\xa9e devant une cour am\\xc3\\xa9ricaine contre Johnson & Johnson et Bayer HealthCare concernant les effets mortels du coagulant Xarelto']\n",
            " [b\"Le projet \\xc2\\xab Proyecto Integrales Morelos \\xc2\\xbb (PIM) est critiqu\\xc3\\xa9 pour violation des droits de l'homme au Mexique.\"]\n",
            " [b'A titre de rappel, la soci\\xc3\\xa9t\\xc3\\xa9 \\xc3\\xa9tait en probation depuis 2017 pour crimes environnementaux et avait pay\\xc3\\xa9 une amende de 40M$']\n",
            " [b\"BP a aussi \\xc3\\xa9t\\xc3\\xa9 accus\\xc3\\xa9e d'avoir revendu les barils achet\\xc3\\xa9s par HLT \\xc3\\xa0 cette m\\xc3\\xaame compagnie, afin de faire croire que HLT disposait de liquidit\\xc3\\xa9s importantes\"]\n",
            " [b'Dans le cadre de conflits sociaux dans deux usines de ces groupes, la police serait intervenue se traduisant par des bless\\xc3\\xa9s et des arrestations']\n",
            " [b\"Daimler reste \\xc3\\xa0 risque quant au diesel : le groupe reste peu transparent et d'autres condamnations le concernant sont attendues.\"]\n",
            " [b\"Le syndicat reproche \\xc3\\xa0 la compagnie d'avoir voulu faire bonne figure en acceptant le dialogue sans r\\xc3\\xa9elles intentions de compromis derri\\xc3\\xa8re\"]\n",
            " [b\"Sanofi fait face \\xc3\\xa0 plusieurs poursuites judiciaires en Suisse accusant le m\\xc3\\xa9dicament anti-\\xc3\\xa9pileptique Depakine de causer des probl\\xc3\\xa8mes de sant\\xc3\\xa9 publique, notamment des troubles cognitifs, des malformations et le d\\xc3\\xa9veloppement de l'autisme chez les enfants de femmes sous traitement\"]\n",
            " [b\"L'enqu\\xc3\\xaate de l'UE, ouverte en 2015, faisait suite \\xc3\\xa0 une plainte du groupe Fairsearch en 2013\"]], shape=(32, 1), dtype=string)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-181-146fe2ea4ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-178-592a8b4e88df>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_preprossing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[0;34m(func, inp, Tout, name)\u001b[0m\n\u001b[1;32m    511\u001b[0m   \"\"\"\n\u001b[1;32m    512\u001b[0m   return _eager_py_func(\n\u001b[0;32m--> 513\u001b[0;31m       func=func, inp=inp, Tout=Tout, name=name, use_tape_cache=True)\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\u001b[0m in \u001b[0;36m_eager_py_func\u001b[0;34m(func, inp, Tout, name, use_tape_cache)\u001b[0m\n\u001b[1;32m    418\u001b[0m           \u001b[0meager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m           use_tape_cache=use_tape_cache)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m   return _internal_py_func(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\u001b[0m in \u001b[0;36m_internal_py_func\u001b[0;34m(func, inp, Tout, stateful, eager, is_grad_func, name, use_tape_cache)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mis_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    349\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[0;34m(input, token, Tout, is_async, name)\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6896\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6897\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6898\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-178-592a8b4e88df>\", line 6, in text_preprossing\n    tokens = nlp(t.decode('utf-8'))\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 401, in __getattr__\n    self.__getattribute__(name)\n\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n\n [Op:EagerPyFunc]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRus14y-YN5F"
      },
      "source": [
        "vocab_size = 10000\n",
        "sequence_length = 600\n",
        "\n",
        "# Use the text vectorization layer to normalize, split, and map strings to\n",
        "# integers. Set output_sequence_length length to pad all samples to same length.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize= clean_text,\n",
        "    #standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='tf-idf',\n",
        "    #output_sequence_length=sequence_length\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "qql50W5XY2Wj",
        "outputId": "eea4634e-d8f4-4914-cb51-b1bf26c33bfa"
      },
      "source": [
        "vectorize_layer.adapt(train_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-3945a2d006a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legacy_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m       \u001b[0mpreprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1923\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   1924\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 1925\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4486\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4487\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4488\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4489\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \"\"\"\n\u001b[1;32m   3134\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3135\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3686\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3687\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3617\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    525\u001b[0m       \u001b[0;31m# so can be squeezed out. We do this here instead of after splitting for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m       \u001b[0;31m# performance reasons - it's more expensive to squeeze a ragged tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSPLIT_ON_WHITESPACE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'int'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NmNWcUQgyN0"
      },
      "source": [
        "### Binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doxc0s-WZBUa"
      },
      "source": [
        "VOCAB_SIZE = 10000\n",
        "\n",
        "binary_vectorize_layer = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='binary')\n",
        "train_text = train_ds.map(lambda text, labels: text)\n",
        "binary_vectorize_layer.adapt(train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mrx-ohN7zmp"
      },
      "source": [
        "def binary_vectorize_text(text, label):\n",
        "  #text = tf.expand_dims(text, -1)\n",
        "  return binary_vectorize_layer(text), label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwv9pm0wjpaV",
        "outputId": "3f4eef89-cd74-4975-e658-8a3de3aaa610"
      },
      "source": [
        "# Retrieve a batch (of 32 reviews and labels) from the dataset\n",
        "text_batch, label_batch = next(iter(train_ds))\n",
        "first_text, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Text\", first_text)\n",
        "print(\"Label\", first_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text tf.Tensor([b'D\\xc3\\xa8s lors le groupe devra payer 50000? par emploi non cr\\xc3\\xa9\\xc3\\xa9.'], shape=(1,), dtype=string)\n",
            "Label tf.Tensor(1623, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeo6RpeUjxWl",
        "outputId": "14d9b7fc-85e1-4ec6-a78d-db76c0a4abaf"
      },
      "source": [
        "print(\"'binary' vectorized question:\", \n",
        "      binary_vectorize_text(first_text, first_label)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'binary' vectorized question: tf.Tensor([[0. 0. 0. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NkVUfjj2GW"
      },
      "source": [
        "binary_train_ds = train_ds.map(binary_vectorize_text)\n",
        "binary_val_ds = val_ds.map(binary_vectorize_text)\n",
        "binary_test_ds = test_ds.map(binary_vectorize_text)\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD3fkB0gi_WN",
        "outputId": "c9ed3608-23b3-4a70-8503-01a81606f51b"
      },
      "source": [
        "def configure_dataset(dataset):\n",
        "  return dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "binary_train_ds = configure_dataset(binary_train_ds)\n",
        "binary_val_ds = configure_dataset(binary_val_ds)\n",
        "binary_test_ds = configure_dataset(binary_test_ds)\n",
        "binary_model = tf.keras.Sequential([layers.Dense(1408)])\n",
        "binary_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "history = binary_model.fit(\n",
        "    binary_train_ds, validation_data=binary_val_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "312/312 [==============================] - 30s 93ms/step - loss: 7.0292 - accuracy: 0.0339 - val_loss: 6.7537 - val_accuracy: 0.0532\n",
            "Epoch 2/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 5.1791 - accuracy: 0.3137 - val_loss: 6.3566 - val_accuracy: 0.1011\n",
            "Epoch 3/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 3.8214 - accuracy: 0.7078 - val_loss: 6.1175 - val_accuracy: 0.1399\n",
            "Epoch 4/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 2.8739 - accuracy: 0.8757 - val_loss: 5.9865 - val_accuracy: 0.1661\n",
            "Epoch 5/10\n",
            "312/312 [==============================] - 28s 89ms/step - loss: 2.2497 - accuracy: 0.9243 - val_loss: 5.9243 - val_accuracy: 0.1742\n",
            "Epoch 6/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 1.8262 - accuracy: 0.9382 - val_loss: 5.9035 - val_accuracy: 0.1787\n",
            "Epoch 7/10\n",
            "312/312 [==============================] - 28s 91ms/step - loss: 1.5233 - accuracy: 0.9460 - val_loss: 5.9084 - val_accuracy: 0.1796\n",
            "Epoch 8/10\n",
            "312/312 [==============================] - 28s 89ms/step - loss: 1.2966 - accuracy: 0.9497 - val_loss: 5.9297 - val_accuracy: 0.1805\n",
            "Epoch 9/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 1.1207 - accuracy: 0.9522 - val_loss: 5.9618 - val_accuracy: 0.1823\n",
            "Epoch 10/10\n",
            "312/312 [==============================] - 28s 89ms/step - loss: 0.9802 - accuracy: 0.9536 - val_loss: 6.0012 - val_accuracy: 0.1796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alj0_5ESmc8S",
        "outputId": "221b21ac-26d4-45ba-f2b3-c0432d496f7e"
      },
      "source": [
        "print(\"Linear model on binary vectorized data:\")\n",
        "print(binary_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear model on binary vectorized data:\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 1408)              14081408  \n",
            "=================================================================\n",
            "Total params: 14,081,408\n",
            "Trainable params: 14,081,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI10gp0PkERd",
        "outputId": "ac42d216-81e2-41b5-a56b-8d0457c6a3a8"
      },
      "source": [
        "binary_loss, binary_accuracy = binary_model.evaluate(binary_test_ds)\n",
        "print(\"Binary model accuracy: {:2.2%}\".format(binary_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 1s 29ms/step - loss: 6.2363 - accuracy: 0.1537\n",
            "Binary model accuracy: 15.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxhhEX6AqOsU",
        "outputId": "8196fbbd-f83c-40f7-abd9-24e32826aac5"
      },
      "source": [
        "export_model = tf.keras.Sequential(\n",
        "    [binary_vectorize_layer, binary_model,\n",
        "     layers.Activation('sigmoid')])\n",
        "\n",
        "export_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Test it with `raw_test_ds`, which yields raw strings\n",
        "loss, accuracy = export_model.evaluate(test_ds)\n",
        "print(\"Accuracy: {:2.2%}\".format(binary_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 1s 33ms/step - loss: 6.2363 - accuracy: 0.1537\n",
            "Accuracy: 15.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXwntrLUqiSJ"
      },
      "source": [
        "def get_string_labels(predicted_scores_batch):\n",
        "  predicted_ints = tf.argmax(predicted_scores_batch, axis=1).numpy()\n",
        "  return [[k for k,v in label_index.items() if v == i][0] for i in predicted_ints]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfBzku5mr5cD",
        "outputId": "2ac74a15-1ec4-4955-e254-7c2a3f6eb62b"
      },
      "source": [
        "predicted_int_labels.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWed_qZftFhe",
        "outputId": "a18453d0-ca3b-4170-e270-a89140a898b7"
      },
      "source": [
        "[k for k,v in label_index.items() if v == 16][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "389"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa_1xAJvrP2S",
        "outputId": "69ca3744-37b6-47e6-9a8a-a81302197065"
      },
      "source": [
        "inputs=[\"EPR de Flamanville: malfaçons\",\n",
        "        \"Redressement fiscal des GAFAM en France\"]\n",
        "predicted_scores = export_model.predict(inputs)\n",
        "predicted_labels = get_string_labels(predicted_scores)\n",
        "for input, label in zip(inputs, predicted_labels):\n",
        "  print(\"Text: \", input)\n",
        "  print(\"Predicted label: \", label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:  EPR de Flamanville: malfaçons\n",
            "Predicted label:  389\n",
            "Text:  Redressement fiscal des GAFAM en France\n",
            "Predicted label:  2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI0C8Ymkwr1S",
        "outputId": "16fe9604-7c2b-4fb8-a28d-991cfdf24942"
      },
      "source": [
        "export_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization_16 (TextV (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 1408)              14081408  \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1408)              0         \n",
            "=================================================================\n",
            "Total params: 14,081,408\n",
            "Trainable params: 14,081,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC2PNBGCw2kb",
        "outputId": "b127a0ae-9e25-4f46-8c32-8df28768ce26"
      },
      "source": [
        "export_model.save('binaryClassif')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: binaryClassif/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ERG_bJ3xQVY",
        "outputId": "ded43e6f-28b2-4435-e58a-70f7878a017e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "QNR08xRnyESn",
        "outputId": "e06b8962-52c7-4783-c59c-0fe29f83d7b9"
      },
      "source": [
        "pd.DataFrame({'label':label_index.values(), 'numControverse':label_index.keys()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>numControverse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>1403</td>\n",
              "      <td>3611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>1404</td>\n",
              "      <td>3612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1405</th>\n",
              "      <td>1405</td>\n",
              "      <td>3613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1406</th>\n",
              "      <td>1406</td>\n",
              "      <td>3614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>1407</td>\n",
              "      <td>3615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1408 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  numControverse\n",
              "0         0              23\n",
              "1         1              57\n",
              "2         2              64\n",
              "3         3              69\n",
              "4         4              77\n",
              "...     ...             ...\n",
              "1403   1403            3611\n",
              "1404   1404            3612\n",
              "1405   1405            3613\n",
              "1406   1406            3614\n",
              "1407   1407            3615\n",
              "\n",
              "[1408 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynpLunx5ypLe",
        "outputId": "0133dc23-e1b4-4d78-de3d-39fa18387261"
      },
      "source": [
        "bq_load_df(\"LabelControv\", pd.DataFrame({'label':label_index.values(), 'numControverse':label_index.keys()}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "table LabelControv load 1408 data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le75hh-6qX_5"
      },
      "source": [
        "### Multi-class Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h31l80deqhlv"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK_Qqt3zqXeU"
      },
      "source": [
        "max_features = 100000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize='lower_and_strip_punctuation',\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    #output_mode='tf-idf',\n",
        "    output_sequence_length=sequence_length\n",
        "    )"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kccsebUsq8MJ"
      },
      "source": [
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQtad_orWRW"
      },
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer(text), label"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3ztBZwErHiV"
      },
      "source": [
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJsZzRe3svby",
        "outputId": "92b83351-3832-4f0c-a984-ad368798a409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(controverses.label.unique())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1408"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX5wcfjzrR3-"
      },
      "source": [
        "embedding_dim = 16"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26Szttt4sdDx",
        "outputId": "dd0a64a7-63d9-4243-f7df-1395208ac6c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  layers.Embedding(max_features + 1, embedding_dim),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Dense(1)])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 16)          1600016   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,600,033\n",
            "Trainable params: 1,600,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7zq0az4sgRy"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIz79S2VuIn3",
        "outputId": "1df3799a-921e-41ba-92e1-c94a8c6293b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_ds"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((None, 250), (None,)), types: (tf.int64, tf.string)>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u2Zb_EFsiV8",
        "outputId": "a0ffe2f2-cd81-4038-c314-4b4746ac4e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-271bfd77b202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     epochs=epochs)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node categorical_crossentropy/Cast (defined at <ipython-input-117-271bfd77b202>:5) ]] [Op:__inference_train_function_3086]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRq_-1tqsk2F"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8o8AfuX6xGV"
      },
      "source": [
        "### Text Classification Guide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZORoffNg9D9a"
      },
      "source": [
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset`\"\n",
        "controverses = get_bq_data(q)\n",
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset_test`\"\n",
        "test = get_bq_data(q)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbL9osYvDI2G"
      },
      "source": [
        "label_index = {k: v for v, k in enumerate(controverses.append(test,ignore_index=True).label.sort_values().unique())}\n",
        "controverses.label = controverses.label.map(lambda x: label_index.get(x))\n",
        "test.label = test.label.map(lambda x: label_index.get(x))"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCrYkIVJ9pyQ",
        "outputId": "c38c55f8-42e2-48c5-e3f1-897e81ad0c57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(controverses))\n",
        "print(len(test))\n",
        "data = ((controverses.Text.values.tolist(),controverses.label.values), \n",
        "        (test.Text.values.tolist(),test.label.values))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11537\n",
            "1254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56SfdC0I_iOB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_num_words_per_sample(sample_texts):\n",
        "    \"\"\"Returns the median number of words per sample given corpus.\n",
        "\n",
        "    # Arguments\n",
        "        sample_texts: list, sample texts.\n",
        "\n",
        "    # Returns\n",
        "        int, median number of words per sample.\n",
        "    \"\"\"\n",
        "    num_words = [len(s.split()) for s in sample_texts]\n",
        "    return np.median(num_words)\n",
        "\n",
        "def plot_sample_length_distribution(sample_texts):\n",
        "    \"\"\"Plots the sample length distribution.\n",
        "\n",
        "    # Arguments\n",
        "        samples_texts: list, sample texts.\n",
        "    \"\"\"\n",
        "    plt.hist([len(s) for s in sample_texts], 50)\n",
        "    plt.xlabel('Length of a sample')\n",
        "    plt.ylabel('Number of samples')\n",
        "    plt.title('Sample length distribution')\n",
        "    plt.show()"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UgirD66_qVX",
        "outputId": "e704cc5a-59dd-49b3-e030-9850e542b734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "num_words = get_num_words_per_sample(controverses.Text.values.tolist())\n",
        "print(num_words)\n",
        "plot_sample_length_distribution(controverses.Text.values.tolist())"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXJLiyz_ARwo"
      },
      "source": [
        "def get_num_classes(labels):\n",
        "    \"\"\"Gets the total number of classes.\n",
        "    # Arguments\n",
        "        labels: list, label values.\n",
        "            There should be at lease one sample for values in the\n",
        "            range (0, num_classes -1)\n",
        "    # Returns\n",
        "        int, total number of classes.\n",
        "    # Raises\n",
        "        ValueError: if any label value in the range(0, num_classes - 1)\n",
        "            is missing or if number of classes is <= 1.\n",
        "    \"\"\"\n",
        "    num_classes = max(labels) + 1\n",
        "    missing_classes = [i for i in range(num_classes) if i not in labels]\n",
        "    if len(missing_classes):\n",
        "        raise ValueError('Missing samples with label value(s) '\n",
        "                         '{missing_classes}. Please make sure you have '\n",
        "                         'at least one sample for every label value '\n",
        "                         'in the range(0, {max_class})'.format(\n",
        "                            missing_classes=missing_classes,\n",
        "                            max_class=num_classes - 1))\n",
        "\n",
        "    if num_classes <= 1:\n",
        "        raise ValueError('Invalid number of labels: {num_classes}.'\n",
        "                         'Please make sure there are at least two classes '\n",
        "                         'of samples'.format(num_classes=num_classes))\n",
        "    return num_classes"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6chqLZ25XZn"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "# Vectorization parameters\n",
        "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
        "NGRAM_RANGE = (1, 2)\n",
        "\n",
        "# Limit on the number of features. We use the top 20K features.\n",
        "TOP_K = 20000\n",
        "\n",
        "# Whether text should be split into word or character n-grams.\n",
        "# One of 'word', 'char'.\n",
        "TOKEN_MODE = 'word'\n",
        "\n",
        "# Minimum document/corpus frequency below which a token will be discarded.\n",
        "MIN_DOCUMENT_FREQUENCY = 2\n",
        "\n",
        "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
        "    \"\"\"Vectorizes texts as n-gram vectors.\n",
        "\n",
        "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
        "\n",
        "    # Arguments\n",
        "        train_texts: list, training text strings.\n",
        "        train_labels: np.ndarray, training labels.\n",
        "        val_texts: list, validation text strings.\n",
        "\n",
        "    # Returns\n",
        "        x_train, x_val: vectorized training and validation texts\n",
        "    \"\"\"\n",
        "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
        "    kwargs = {\n",
        "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
        "            'dtype': 'int32',\n",
        "            'strip_accents': 'unicode',\n",
        "            'decode_error': 'replace',\n",
        "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
        "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
        "    }\n",
        "    vectorizer = TfidfVectorizer(**kwargs)\n",
        "\n",
        "    # Learn vocabulary from training texts and vectorize training texts.\n",
        "    x_train = vectorizer.fit_transform(train_texts)\n",
        "\n",
        "    # Vectorize validation texts.\n",
        "    x_val = vectorizer.transform(val_texts)\n",
        "\n",
        "    # Select top 'k' of the vectorized features.\n",
        "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
        "    selector.fit(x_train, train_labels)\n",
        "    x_train = selector.transform(x_train).astype('float32')\n",
        "    x_val = selector.transform(x_val).astype('float32')\n",
        "    return x_train, x_val"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BstM-X3x-OGR"
      },
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7DxqpgD8UPv"
      },
      "source": [
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "\n",
        "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
        "\n",
        "    for _ in range(layers-1):\n",
        "        model.add(Dense(units=units, activation='relu'))\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(units=op_units, activation=op_activation))\n",
        "    return model"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMMvWTvN8fs2"
      },
      "source": [
        "def train_ngram_model(data,\n",
        "                      learning_rate=1e-3,\n",
        "                      epochs=1000,\n",
        "                      batch_size=128,\n",
        "                      layers=2,\n",
        "                      units=64,\n",
        "                      dropout_rate=0.2):\n",
        "    \"\"\"Trains n-gram model on the given dataset.\n",
        "\n",
        "    # Arguments\n",
        "        data: tuples of training and test texts and labels.\n",
        "        learning_rate: float, learning rate for training model.\n",
        "        epochs: int, number of epochs.\n",
        "        batch_size: int, number of samples per batch.\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of Dense layers in the model.\n",
        "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
        "\n",
        "    # Raises\n",
        "        ValueError: If validation data has label values which were not seen\n",
        "            in the training data.\n",
        "    \"\"\"\n",
        "    # Get the data.\n",
        "    (train_texts, train_labels), (val_texts, val_labels) = data\n",
        "\n",
        "    # Verify that validation labels are in the same range as training labels.\n",
        "    num_classes = get_num_classes(train_labels)\n",
        "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
        "    if len(unexpected_labels):\n",
        "        raise ValueError('Unexpected label values found in the validation set:'\n",
        "                          ' {unexpected_labels}. Please make sure that the '\n",
        "                          'labels in the validation set are in the same range '\n",
        "                          'as training labels.'.format(\n",
        "                              unexpected_labels=unexpected_labels))\n",
        "\n",
        "    # Vectorize texts.\n",
        "    x_train, x_val = ngram_vectorize(\n",
        "        train_texts, train_labels, val_texts)\n",
        "\n",
        "    # Create model instance.\n",
        "    model = mlp_model(layers=layers,\n",
        "                      units=units,\n",
        "                      dropout_rate=dropout_rate,\n",
        "                      input_shape=x_train.shape[1:],\n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    # Compile model with learning parameters.\n",
        "    if num_classes == 2:\n",
        "        loss = 'binary_crossentropy'\n",
        "    else:\n",
        "        loss = 'sparse_categorical_crossentropy'\n",
        "    #optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(optimizer='adam', loss=loss, metrics=['acc'])\n",
        "\n",
        "    # Create callback for early stopping on validation loss. If the loss does\n",
        "    # not decrease in two consecutive tries, stop training.\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]\n",
        "\n",
        "    # Train and validate model.\n",
        "    history = model.fit(\n",
        "            x_train,\n",
        "            train_labels,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, val_labels),\n",
        "            verbose=2,  # Logs once per epoch.\n",
        "            batch_size=batch_size)\n",
        "\n",
        "    # Print results.\n",
        "    history = history.history\n",
        "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
        "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
        "\n",
        "    # Save model.\n",
        "    model.save('Controverses_Classification')\n",
        "    return history['val_acc'][-1], history['val_loss'][-1]"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JICK6OZGhav",
        "outputId": "f35bf158-dc80-4810-c98b-b6b8887d7b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "val_acc, val_loss = train_ngram_model(data,\n",
        "                      learning_rate=1e-3,\n",
        "                      epochs=1000,\n",
        "                      batch_size=128,\n",
        "                      layers=2,\n",
        "                      units=64,\n",
        "                      dropout_rate=0.2)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1817: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-db774fc0e11e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                       dropout_rate=0.2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-197-a5f61154e774>\u001b[0m in \u001b[0;36mtrain_ngram_model\u001b[0;34m(data, learning_rate, epochs, batch_size, layers, units, dropout_rate)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Logs once per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Print results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 _r=1):\n\u001b[1;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:862 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:802 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:380 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:421 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:235 call\n        lambda: array_ops.identity(inputs))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/control_flow_util.py:110 smart_cond\n        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py:56 smart_cond\n        return true_fn()\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:232 dropped_inputs\n        rate=self.rate)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:549 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5229 dropout\n        return dropout_v2(x, rate, noise_shape=noise_shape, seed=seed, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5311 dropout_v2\n        x = ops.convert_to_tensor(x, name=\"x\")\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:346 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:272 constant\n        allow_broadcast=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:290 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlei5CF89l-q"
      },
      "source": [
        "learning_rate=1e-3\n",
        "epochs=1000\n",
        "batch_size=128\n",
        "layers=2\n",
        "units=1407\n",
        "dropout_rate=0.2"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDZA9c3T9Vci"
      },
      "source": [
        "(train_texts, train_labels), (val_texts, val_labels) = data"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmSQ_ptiEEM4"
      },
      "source": [
        "num_classes = get_num_classes(train_labels)\n",
        "unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
        "if len(unexpected_labels):\n",
        "    raise ValueError('Unexpected label values found in the validation set:'\n",
        "                      ' {unexpected_labels}. Please make sure that the '\n",
        "                      'labels in the validation set are in the same range '\n",
        "                      'as training labels.'.format(\n",
        "                          unexpected_labels=unexpected_labels))"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_NUb5MQEGtA",
        "outputId": "d3c66912-cacf-49f9-fb7c-2063c5b4a5d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train, x_val = ngram_vectorize(\n",
        "    train_texts, train_labels, val_texts)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1817: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
            "  UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J4_OuIMErQQ"
      },
      "source": [
        "model = mlp_model(layers=layers,\n",
        "                      units=units,\n",
        "                      dropout_rate=dropout_rate,\n",
        "                      input_shape=x_train.shape[1:],\n",
        "                      num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrfbDmzFEUF_",
        "outputId": "31f75103-9e01-4335-8777-a54a65a07b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss = 'sparse_categorical_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "model.compile(optimizer='adam', loss=loss, metrics=['acc'])"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNB3w2zZEvHV"
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgMItysuGvL5",
        "outputId": "c60ab39d-cadf-4780-9277-d1dcec3d4383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_val"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1254x20000 sparse matrix of type '<class 'numpy.float32'>'\n",
              "\twith 26467 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIDbZrvXFcF1",
        "outputId": "9d9aeac9-20af-42db-e5f0-70a7fb042c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(\n",
        "            x_train,\n",
        "            train_labels,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, val_labels),\n",
        "            verbose=2,  # Logs once per epoch.\n",
        "            batch_size=batch_size)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-196-3718bc3b86e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Logs once per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             batch_size=batch_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 _r=1):\n\u001b[1;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:862 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:802 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:380 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:421 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:235 call\n        lambda: array_ops.identity(inputs))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/control_flow_util.py:110 smart_cond\n        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py:56 smart_cond\n        return true_fn()\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:232 dropped_inputs\n        rate=self.rate)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:549 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5229 dropout\n        return dropout_v2(x, rate, noise_shape=noise_shape, seed=seed, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5311 dropout_v2\n        x = ops.convert_to_tensor(x, name=\"x\")\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:346 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:272 constant\n        allow_broadcast=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:290 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUX8qf6DFfQ0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}