{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YvYh/FluxWeb/blob/main/Model_Controverses3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7JxozYqb4u"
      },
      "source": [
        "# **BQ**: Get/Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoWR0fEEVc2j"
      },
      "source": [
        "from google.cloud import bigquery\n",
        "json_path = 'poc-bigdata.json'\n",
        "bigquery_client = bigquery.Client.from_service_account_json(json_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mxZ0VONVJ8y"
      },
      "source": [
        "def get_bq_data(query):\n",
        "  query_job = bigquery_client.query(query)\n",
        "  rows = query_job.result()\n",
        "  data = rows.to_dataframe()\n",
        "  return data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14I5mpYIVr4X"
      },
      "source": [
        "def bq_load_df(name, df):\n",
        "    dataset_ref = bigquery_client.dataset('FluxWeb_Prediction')\n",
        "    table_ref = dataset_ref.table(name)\n",
        "    \n",
        "    \n",
        "    job_config = bigquery.LoadJobConfig()\n",
        "    job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
        "    if name == 'Controverses_bert':\n",
        "      job_config.schema = get_bigquery_schema()\n",
        "    else:\n",
        "      job_config.autodetect=True\n",
        " \n",
        "    load_job = bigquery_client.load_table_from_dataframe(\n",
        "        df,\n",
        "        table_ref,\n",
        "        job_config=job_config)\n",
        " \n",
        "    assert load_job.job_type == 'load'\n",
        " \n",
        "    load_job.result()  # Waits for table load to complete.\n",
        " \n",
        "    assert load_job.state == 'DONE'\n",
        "    print('table {} load {} data.'.format(name, len(df)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBKdP9-8pfuW"
      },
      "source": [
        "# **TensorFlow**:  TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTVq5YN56-Fc"
      },
      "source": [
        "### Get Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nvtPr9q7tnu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4Ln9vXYpkRX"
      },
      "source": [
        " \"\"\"SELECT DISTINCT NumControverse as label, Titre as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "UNION ALL \n",
        "SELECT DISTINCT NumControverse as label, Commentaire as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "WHERE Commentaire is not null and length(Commentaire)>5\n",
        "UNION ALL \n",
        "SELECT DISTINCT NumControverse as label, Informations as Text\n",
        "FROM `poc-bigdata.FluxWeb_Prediction.Controverses_prd`\n",
        "WHERE Informations is not null\n",
        "\"\"\"\n",
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset`\"\n",
        "controverses = get_bq_data(q)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqtPfh_EpdkM"
      },
      "source": [
        "#controverses['Text_clean']=controverses.Text.apply(text_preprossing)\n",
        "controverses = controverses[['label','Text']]"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "MSdOrlfrz95b",
        "outputId": "38d8eb49-1c7f-4425-d166-1ebe24418360"
      },
      "source": [
        "print(len(controverses))\n",
        "print(len(controverses.label.unique()))\n",
        "controverses.head()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11537\n",
            "1408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2866</td>\n",
              "      <td>Révélation d'un scandale comptable survenu en ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389</td>\n",
              "      <td>EPR de Flamanville: malfaçons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2543</td>\n",
              "      <td>Condamnation suite à des déversements dans des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3506</td>\n",
              "      <td>Poursuites aux Etats-Unis en lien avec les émi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3016</td>\n",
              "      <td>Incendie dans une usine de Lubrizol à Rouen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               Text\n",
              "0   2866  Révélation d'un scandale comptable survenu en ...\n",
              "1    389                      EPR de Flamanville: malfaçons\n",
              "2   2543  Condamnation suite à des déversements dans des...\n",
              "3   3506  Poursuites aux Etats-Unis en lien avec les émi...\n",
              "4   3016        Incendie dans une usine de Lubrizol à Rouen"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCNXhJFWW7q7",
        "outputId": "bbd67114-9b73-46a1-b17c-7e1aab27e3ca"
      },
      "source": [
        "controverses['label'] = controverses['label'].astype('str')\n",
        "controverses.label.dtypes"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xxz936WnQPs",
        "outputId": "f7b1ad0b-ecdc-4ed0-884e-2fce551b7e20"
      },
      "source": [
        "controverses.label.sort_values().unique()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1023', '1082', '1092', ..., '94', '952', '955'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T41MC8evoEWV"
      },
      "source": [
        "#label_index = {k: v for v, k in enumerate(controverses.label.sort_values().unique())}\n",
        "#controverses.label = controverses.label.map(lambda x: label_index.get(x))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYLWAp_aqyX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7747d9-20b2-41aa-bac2-b7419c852f52"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#train, test = train_test_split(controverses, test_size=0.04)\n",
        "train, val = train_test_split(controverses, test_size=0.1)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "#print(len(test), 'test examples')"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10383 train examples\n",
            "1154 validation examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1zlcJ_AXpxN",
        "outputId": "0cab0a47-0224-45c9-ca2e-0afab703a336"
      },
      "source": [
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset_test`\"\n",
        "test = get_bq_data(q)\n",
        "print(len(test), 'test examples')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1254 test examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQTi0l4eX33G"
      },
      "source": [
        "test['label'] = test['label'].astype('str')"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ5e1rs7tvpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd8a77b3-d959-4eee-a332-966bfbfeb766"
      },
      "source": [
        "train.Text"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6292     La firme a indiqué qu'elle décidera dans les p...\n",
              "253      Les émetteurs de titres restaurant lourdement ...\n",
              "180      La gamme AmazonBasics poserait des risques aux...\n",
              "9525     Les deux parties se sont précédemment déjà réu...\n",
              "1004     L'autorité allemande de la concurrence inflige...\n",
              "                               ...                        \n",
              "9403     Orange anciennement France Télécom, a été cond...\n",
              "8592     Les tribus indigènes et les écologistes ont cr...\n",
              "11482    La Commission européenne, par l'intermédiaire ...\n",
              "1129     Endesa accusé d'avoir provoqué la mort de 255 ...\n",
              "9940      La Swedbank et SEB font déjà l'objet d'une en...\n",
              "Name: Text, Length: 10383, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPJ119Tpp_0"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNSuVrS9rD5L"
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('label')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dataframe.Text, labels.values))\n",
        "  #ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNdFIf0Asv-Z"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 32\n",
        "raw_train_ds = df_to_dataset(train)\n",
        "raw_test_ds = df_to_dataset(test)\n",
        "raw_val_ds= df_to_dataset(val)\n",
        "raw_train_ds = raw_train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "raw_test_ds = raw_test_ds.prefetch(tf.data.AUTOTUNE)\n",
        "raw_val_ds = raw_val_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkpYs1_6s6rO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98792b3-df6a-48a5-c2b0-904bafb0669c"
      },
      "source": [
        "for example, label in raw_train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print('texts: ', example.numpy()[i])\n",
        "    print('labels: ', label.numpy()[i])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  b\"La banque dispose d'un d\\xc3\\xa9lai de vingt jours pour pr\\xc3\\xa9senter un plan de fermeture de sa succursale\"\n",
            "labels:  b'2348'\n",
            "texts:  b\"On ne sait pas pour le moment si d'autres pays sont concern\\xc3\\xa9s mais il est fort possible que ce soit le cas\"\n",
            "labels:  b'2572'\n",
            "texts:  b\"Un membre d'Animal Equality a travaill\\xc3\\xa9 de fa\\xc3\\xa7on dissimul\\xc3\\xa9e pour Moy Park qui d\\xc3\\xa9tient un tiers du march\\xc3\\xa9 de la volaille au Royaume-Uni et vend aux grandes surfaces comme Tesco et Ocado\"\n",
            "labels:  b'2942'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NmNWcUQgyN0"
      },
      "source": [
        "### Binary classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doxc0s-WZBUa"
      },
      "source": [
        "VOCAB_SIZE = 10000\n",
        "\n",
        "binary_vectorize_layer = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='binary')\n",
        "train_text = train_ds.map(lambda text, labels: text)\n",
        "binary_vectorize_layer.adapt(train_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mrx-ohN7zmp"
      },
      "source": [
        "def binary_vectorize_text(text, label):\n",
        "  #text = tf.expand_dims(text, -1)\n",
        "  return binary_vectorize_layer(text), label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwv9pm0wjpaV",
        "outputId": "3f4eef89-cd74-4975-e658-8a3de3aaa610"
      },
      "source": [
        "# Retrieve a batch (of 32 reviews and labels) from the dataset\n",
        "text_batch, label_batch = next(iter(train_ds))\n",
        "first_text, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Text\", first_text)\n",
        "print(\"Label\", first_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text tf.Tensor([b'D\\xc3\\xa8s lors le groupe devra payer 50000? par emploi non cr\\xc3\\xa9\\xc3\\xa9.'], shape=(1,), dtype=string)\n",
            "Label tf.Tensor(1623, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeo6RpeUjxWl",
        "outputId": "14d9b7fc-85e1-4ec6-a78d-db76c0a4abaf"
      },
      "source": [
        "print(\"'binary' vectorized question:\", \n",
        "      binary_vectorize_text(first_text, first_label)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'binary' vectorized question: tf.Tensor([[0. 0. 0. ... 0. 0. 0.]], shape=(1, 10000), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NkVUfjj2GW"
      },
      "source": [
        "binary_train_ds = train_ds.map(binary_vectorize_text)\n",
        "binary_val_ds = val_ds.map(binary_vectorize_text)\n",
        "binary_test_ds = test_ds.map(binary_vectorize_text)\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD3fkB0gi_WN",
        "outputId": "c9ed3608-23b3-4a70-8503-01a81606f51b"
      },
      "source": [
        "def configure_dataset(dataset):\n",
        "  return dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "binary_train_ds = configure_dataset(binary_train_ds)\n",
        "binary_val_ds = configure_dataset(binary_val_ds)\n",
        "binary_test_ds = configure_dataset(binary_test_ds)\n",
        "binary_model = tf.keras.Sequential([layers.Dense(1408)])\n",
        "binary_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "history = binary_model.fit(\n",
        "    binary_train_ds, validation_data=binary_val_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "312/312 [==============================] - 30s 93ms/step - loss: 7.0292 - accuracy: 0.0339 - val_loss: 6.7537 - val_accuracy: 0.0532\n",
            "Epoch 2/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 5.1791 - accuracy: 0.3137 - val_loss: 6.3566 - val_accuracy: 0.1011\n",
            "Epoch 3/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 3.8214 - accuracy: 0.7078 - val_loss: 6.1175 - val_accuracy: 0.1399\n",
            "Epoch 4/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 2.8739 - accuracy: 0.8757 - val_loss: 5.9865 - val_accuracy: 0.1661\n",
            "Epoch 5/10\n",
            "312/312 [==============================] - 28s 89ms/step - loss: 2.2497 - accuracy: 0.9243 - val_loss: 5.9243 - val_accuracy: 0.1742\n",
            "Epoch 6/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 1.8262 - accuracy: 0.9382 - val_loss: 5.9035 - val_accuracy: 0.1787\n",
            "Epoch 7/10\n",
            "312/312 [==============================] - 28s 91ms/step - loss: 1.5233 - accuracy: 0.9460 - val_loss: 5.9084 - val_accuracy: 0.1796\n",
            "Epoch 8/10\n",
            "312/312 [==============================] - 28s 89ms/step - loss: 1.2966 - accuracy: 0.9497 - val_loss: 5.9297 - val_accuracy: 0.1805\n",
            "Epoch 9/10\n",
            "312/312 [==============================] - 28s 90ms/step - loss: 1.1207 - accuracy: 0.9522 - val_loss: 5.9618 - val_accuracy: 0.1823\n",
            "Epoch 10/10\n",
            "312/312 [==============================] - 28s 89ms/step - loss: 0.9802 - accuracy: 0.9536 - val_loss: 6.0012 - val_accuracy: 0.1796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alj0_5ESmc8S",
        "outputId": "221b21ac-26d4-45ba-f2b3-c0432d496f7e"
      },
      "source": [
        "print(\"Linear model on binary vectorized data:\")\n",
        "print(binary_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear model on binary vectorized data:\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 1408)              14081408  \n",
            "=================================================================\n",
            "Total params: 14,081,408\n",
            "Trainable params: 14,081,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI10gp0PkERd",
        "outputId": "ac42d216-81e2-41b5-a56b-8d0457c6a3a8"
      },
      "source": [
        "binary_loss, binary_accuracy = binary_model.evaluate(binary_test_ds)\n",
        "print(\"Binary model accuracy: {:2.2%}\".format(binary_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 1s 29ms/step - loss: 6.2363 - accuracy: 0.1537\n",
            "Binary model accuracy: 15.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxhhEX6AqOsU",
        "outputId": "8196fbbd-f83c-40f7-abd9-24e32826aac5"
      },
      "source": [
        "export_model = tf.keras.Sequential(\n",
        "    [binary_vectorize_layer, binary_model,\n",
        "     layers.Activation('sigmoid')])\n",
        "\n",
        "export_model.compile(\n",
        "    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# Test it with `raw_test_ds`, which yields raw strings\n",
        "loss, accuracy = export_model.evaluate(test_ds)\n",
        "print(\"Accuracy: {:2.2%}\".format(binary_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 1s 33ms/step - loss: 6.2363 - accuracy: 0.1537\n",
            "Accuracy: 15.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXwntrLUqiSJ"
      },
      "source": [
        "def get_string_labels(predicted_scores_batch):\n",
        "  predicted_ints = tf.argmax(predicted_scores_batch, axis=1).numpy()\n",
        "  return [[k for k,v in label_index.items() if v == i][0] for i in predicted_ints]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfBzku5mr5cD",
        "outputId": "2ac74a15-1ec4-4955-e254-7c2a3f6eb62b"
      },
      "source": [
        "predicted_int_labels.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWed_qZftFhe",
        "outputId": "a18453d0-ca3b-4170-e270-a89140a898b7"
      },
      "source": [
        "[k for k,v in label_index.items() if v == 16][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "389"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa_1xAJvrP2S",
        "outputId": "69ca3744-37b6-47e6-9a8a-a81302197065"
      },
      "source": [
        "inputs=[\"EPR de Flamanville: malfaçons\",\n",
        "        \"Redressement fiscal des GAFAM en France\"]\n",
        "predicted_scores = export_model.predict(inputs)\n",
        "predicted_labels = get_string_labels(predicted_scores)\n",
        "for input, label in zip(inputs, predicted_labels):\n",
        "  print(\"Text: \", input)\n",
        "  print(\"Predicted label: \", label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text:  EPR de Flamanville: malfaçons\n",
            "Predicted label:  389\n",
            "Text:  Redressement fiscal des GAFAM en France\n",
            "Predicted label:  2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI0C8Ymkwr1S",
        "outputId": "16fe9604-7c2b-4fb8-a28d-991cfdf24942"
      },
      "source": [
        "export_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization_16 (TextV (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 1408)              14081408  \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1408)              0         \n",
            "=================================================================\n",
            "Total params: 14,081,408\n",
            "Trainable params: 14,081,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC2PNBGCw2kb",
        "outputId": "b127a0ae-9e25-4f46-8c32-8df28768ce26"
      },
      "source": [
        "export_model.save('binaryClassif')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: binaryClassif/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ERG_bJ3xQVY",
        "outputId": "ded43e6f-28b2-4435-e58a-70f7878a017e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "QNR08xRnyESn",
        "outputId": "e06b8962-52c7-4783-c59c-0fe29f83d7b9"
      },
      "source": [
        "pd.DataFrame({'label':label_index.values(), 'numControverse':label_index.keys()})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>numControverse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1403</th>\n",
              "      <td>1403</td>\n",
              "      <td>3611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>1404</td>\n",
              "      <td>3612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1405</th>\n",
              "      <td>1405</td>\n",
              "      <td>3613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1406</th>\n",
              "      <td>1406</td>\n",
              "      <td>3614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>1407</td>\n",
              "      <td>3615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1408 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  numControverse\n",
              "0         0              23\n",
              "1         1              57\n",
              "2         2              64\n",
              "3         3              69\n",
              "4         4              77\n",
              "...     ...             ...\n",
              "1403   1403            3611\n",
              "1404   1404            3612\n",
              "1405   1405            3613\n",
              "1406   1406            3614\n",
              "1407   1407            3615\n",
              "\n",
              "[1408 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynpLunx5ypLe",
        "outputId": "0133dc23-e1b4-4d78-de3d-39fa18387261"
      },
      "source": [
        "bq_load_df(\"LabelControv\", pd.DataFrame({'label':label_index.values(), 'numControverse':label_index.keys()}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "table LabelControv load 1408 data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8o8AfuX6xGV"
      },
      "source": [
        "# Text Classification Guide  \n",
        "https://developers.google.com/machine-learning/guides/text-classification/step-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZORoffNg9D9a"
      },
      "source": [
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset`\"\n",
        "controverses = get_bq_data(q)\n",
        "q=\"SELECT label, Text FROM `poc-bigdata.FluxWeb_Prediction.Controverse_dataset_test`\"\n",
        "test = get_bq_data(q)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbL9osYvDI2G"
      },
      "source": [
        "label_index = {k: v for v, k in enumerate(controverses.append(test,ignore_index=True).label.sort_values().unique())}\n",
        "controverses.label = controverses.label.map(lambda x: label_index.get(x))\n",
        "test.label = test.label.map(lambda x: label_index.get(x))"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCrYkIVJ9pyQ",
        "outputId": "c38c55f8-42e2-48c5-e3f1-897e81ad0c57"
      },
      "source": [
        "print(len(controverses))\n",
        "print(len(test))\n",
        "data = ((controverses.Text.values.tolist(),controverses.label.values), \n",
        "        (test.Text.values.tolist(),test.label.values))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11537\n",
            "1254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56SfdC0I_iOB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_num_words_per_sample(sample_texts):\n",
        "    \"\"\"Returns the median number of words per sample given corpus.\n",
        "\n",
        "    # Arguments\n",
        "        sample_texts: list, sample texts.\n",
        "\n",
        "    # Returns\n",
        "        int, median number of words per sample.\n",
        "    \"\"\"\n",
        "    num_words = [len(s.split()) for s in sample_texts]\n",
        "    return np.median(num_words)\n",
        "\n",
        "def plot_sample_length_distribution(sample_texts):\n",
        "    \"\"\"Plots the sample length distribution.\n",
        "\n",
        "    # Arguments\n",
        "        samples_texts: list, sample texts.\n",
        "    \"\"\"\n",
        "    plt.hist([len(s) for s in sample_texts], 50)\n",
        "    plt.xlabel('Length of a sample')\n",
        "    plt.ylabel('Number of samples')\n",
        "    plt.title('Sample length distribution')\n",
        "    plt.show()"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "-UgirD66_qVX",
        "outputId": "e704cc5a-59dd-49b3-e030-9850e542b734"
      },
      "source": [
        "num_words = get_num_words_per_sample(controverses.Text.values.tolist())\n",
        "print(num_words)\n",
        "plot_sample_length_distribution(controverses.Text.values.tolist())"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXJLiyz_ARwo"
      },
      "source": [
        "def get_num_classes(labels):\n",
        "    \"\"\"Gets the total number of classes.\n",
        "    # Arguments\n",
        "        labels: list, label values.\n",
        "            There should be at lease one sample for values in the\n",
        "            range (0, num_classes -1)\n",
        "    # Returns\n",
        "        int, total number of classes.\n",
        "    # Raises\n",
        "        ValueError: if any label value in the range(0, num_classes - 1)\n",
        "            is missing or if number of classes is <= 1.\n",
        "    \"\"\"\n",
        "    num_classes = max(labels) + 1\n",
        "    missing_classes = [i for i in range(num_classes) if i not in labels]\n",
        "    if len(missing_classes):\n",
        "        raise ValueError('Missing samples with label value(s) '\n",
        "                         '{missing_classes}. Please make sure you have '\n",
        "                         'at least one sample for every label value '\n",
        "                         'in the range(0, {max_class})'.format(\n",
        "                            missing_classes=missing_classes,\n",
        "                            max_class=num_classes - 1))\n",
        "\n",
        "    if num_classes <= 1:\n",
        "        raise ValueError('Invalid number of labels: {num_classes}.'\n",
        "                         'Please make sure there are at least two classes '\n",
        "                         'of samples'.format(num_classes=num_classes))\n",
        "    return num_classes"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6chqLZ25XZn"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "# Vectorization parameters\n",
        "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
        "NGRAM_RANGE = (1, 2)\n",
        "\n",
        "# Limit on the number of features. We use the top 20K features.\n",
        "TOP_K = 20000\n",
        "\n",
        "# Whether text should be split into word or character n-grams.\n",
        "# One of 'word', 'char'.\n",
        "TOKEN_MODE = 'word'\n",
        "\n",
        "# Minimum document/corpus frequency below which a token will be discarded.\n",
        "MIN_DOCUMENT_FREQUENCY = 2\n",
        "\n",
        "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
        "    \"\"\"Vectorizes texts as n-gram vectors.\n",
        "\n",
        "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
        "\n",
        "    # Arguments\n",
        "        train_texts: list, training text strings.\n",
        "        train_labels: np.ndarray, training labels.\n",
        "        val_texts: list, validation text strings.\n",
        "\n",
        "    # Returns\n",
        "        x_train, x_val: vectorized training and validation texts\n",
        "    \"\"\"\n",
        "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
        "    kwargs = {\n",
        "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
        "            'dtype': 'int32',\n",
        "            'strip_accents': 'unicode',\n",
        "            'decode_error': 'replace',\n",
        "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
        "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
        "    }\n",
        "    vectorizer = TfidfVectorizer(**kwargs)\n",
        "\n",
        "    # Learn vocabulary from training texts and vectorize training texts.\n",
        "    x_train = vectorizer.fit_transform(train_texts)\n",
        "\n",
        "    # Vectorize validation texts.\n",
        "    x_val = vectorizer.transform(val_texts)\n",
        "\n",
        "    # Select top 'k' of the vectorized features.\n",
        "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
        "    selector.fit(x_train, train_labels)\n",
        "    x_train = selector.transform(x_train).astype('float32')\n",
        "    x_val = selector.transform(x_val).astype('float32')\n",
        "    return x_train, x_val"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BstM-X3x-OGR"
      },
      "source": [
        "def _get_last_layer_units_and_activation(num_classes):\n",
        "    \"\"\"Gets the # units and activation function for the last network layer.\n",
        "\n",
        "    # Arguments\n",
        "        num_classes: int, number of classes.\n",
        "\n",
        "    # Returns\n",
        "        units, activation values.\n",
        "    \"\"\"\n",
        "    if num_classes == 2:\n",
        "        activation = 'sigmoid'\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "        units = num_classes\n",
        "    return units, activation"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7DxqpgD8UPv"
      },
      "source": [
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.layers import Dropout\n",
        "\n",
        "def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n",
        "    \"\"\"Creates an instance of a multi-layer perceptron model.\n",
        "\n",
        "    # Arguments\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of the layers.\n",
        "        dropout_rate: float, percentage of input to drop at Dropout layers.\n",
        "        input_shape: tuple, shape of input to the model.\n",
        "        num_classes: int, number of output classes.\n",
        "\n",
        "    # Returns\n",
        "        An MLP model instance.\n",
        "    \"\"\"\n",
        "    op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n",
        "    model = models.Sequential()\n",
        "    model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n",
        "\n",
        "    for _ in range(layers-1):\n",
        "        model.add(Dense(units=units, activation='relu'))\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    model.add(Dense(units=op_units, activation=op_activation))\n",
        "    return model"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMMvWTvN8fs2"
      },
      "source": [
        "def train_ngram_model(data,\n",
        "                      learning_rate=1e-3,\n",
        "                      epochs=1000,\n",
        "                      batch_size=128,\n",
        "                      layers=2,\n",
        "                      units=64,\n",
        "                      dropout_rate=0.2):\n",
        "    \"\"\"Trains n-gram model on the given dataset.\n",
        "\n",
        "    # Arguments\n",
        "        data: tuples of training and test texts and labels.\n",
        "        learning_rate: float, learning rate for training model.\n",
        "        epochs: int, number of epochs.\n",
        "        batch_size: int, number of samples per batch.\n",
        "        layers: int, number of `Dense` layers in the model.\n",
        "        units: int, output dimension of Dense layers in the model.\n",
        "        dropout_rate: float: percentage of input to drop at Dropout layers.\n",
        "\n",
        "    # Raises\n",
        "        ValueError: If validation data has label values which were not seen\n",
        "            in the training data.\n",
        "    \"\"\"\n",
        "    # Get the data.\n",
        "    (train_texts, train_labels), (val_texts, val_labels) = data\n",
        "\n",
        "    # Verify that validation labels are in the same range as training labels.\n",
        "    num_classes = get_num_classes(train_labels)\n",
        "    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
        "    if len(unexpected_labels):\n",
        "        raise ValueError('Unexpected label values found in the validation set:'\n",
        "                          ' {unexpected_labels}. Please make sure that the '\n",
        "                          'labels in the validation set are in the same range '\n",
        "                          'as training labels.'.format(\n",
        "                              unexpected_labels=unexpected_labels))\n",
        "\n",
        "    # Vectorize texts.\n",
        "    x_train, x_val = ngram_vectorize(\n",
        "        train_texts, train_labels, val_texts)\n",
        "\n",
        "    # Create model instance.\n",
        "    model = mlp_model(layers=layers,\n",
        "                      units=units,\n",
        "                      dropout_rate=dropout_rate,\n",
        "                      input_shape=x_train.shape[1:],\n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    # Compile model with learning parameters.\n",
        "    if num_classes == 2:\n",
        "        loss = 'binary_crossentropy'\n",
        "    else:\n",
        "        loss = 'sparse_categorical_crossentropy'\n",
        "    #optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(optimizer='adam', loss=loss, metrics=['acc'])\n",
        "\n",
        "    # Create callback for early stopping on validation loss. If the loss does\n",
        "    # not decrease in two consecutive tries, stop training.\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]\n",
        "\n",
        "    # Train and validate model.\n",
        "    history = model.fit(\n",
        "            x_train,\n",
        "            train_labels,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, val_labels),\n",
        "            verbose=2,  # Logs once per epoch.\n",
        "            batch_size=batch_size)\n",
        "\n",
        "    # Print results.\n",
        "    history = history.history\n",
        "    print('Validation accuracy: {acc}, loss: {loss}'.format(\n",
        "            acc=history['val_acc'][-1], loss=history['val_loss'][-1]))\n",
        "\n",
        "    # Save model.\n",
        "    model.save('Controverses_Classification')\n",
        "    return history['val_acc'][-1], history['val_loss'][-1]"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4JICK6OZGhav",
        "outputId": "f35bf158-dc80-4810-c98b-b6b8887d7b17"
      },
      "source": [
        "val_acc, val_loss = train_ngram_model(data,\n",
        "                      learning_rate=1e-3,\n",
        "                      epochs=1000,\n",
        "                      batch_size=128,\n",
        "                      layers=2,\n",
        "                      units=64,\n",
        "                      dropout_rate=0.2)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1817: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-db774fc0e11e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                       dropout_rate=0.2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-197-a5f61154e774>\u001b[0m in \u001b[0;36mtrain_ngram_model\u001b[0;34m(data, learning_rate, epochs, batch_size, layers, units, dropout_rate)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Logs once per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Print results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 _r=1):\n\u001b[1;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:862 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:802 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:380 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:421 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:235 call\n        lambda: array_ops.identity(inputs))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/control_flow_util.py:110 smart_cond\n        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py:56 smart_cond\n        return true_fn()\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:232 dropped_inputs\n        rate=self.rate)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:549 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5229 dropout\n        return dropout_v2(x, rate, noise_shape=noise_shape, seed=seed, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5311 dropout_v2\n        x = ops.convert_to_tensor(x, name=\"x\")\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:346 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:272 constant\n        allow_broadcast=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:290 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlei5CF89l-q"
      },
      "source": [
        "learning_rate=1e-3\n",
        "epochs=1000\n",
        "batch_size=128\n",
        "layers=2\n",
        "units=1407\n",
        "dropout_rate=0.2"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDZA9c3T9Vci"
      },
      "source": [
        "(train_texts, train_labels), (val_texts, val_labels) = data"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmSQ_ptiEEM4"
      },
      "source": [
        "num_classes = get_num_classes(train_labels)\n",
        "unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n",
        "if len(unexpected_labels):\n",
        "    raise ValueError('Unexpected label values found in the validation set:'\n",
        "                      ' {unexpected_labels}. Please make sure that the '\n",
        "                      'labels in the validation set are in the same range '\n",
        "                      'as training labels.'.format(\n",
        "                          unexpected_labels=unexpected_labels))"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_NUb5MQEGtA",
        "outputId": "d3c66912-cacf-49f9-fb7c-2063c5b4a5d9"
      },
      "source": [
        "x_train, x_val = ngram_vectorize(\n",
        "    train_texts, train_labels, val_texts)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:1817: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
            "  UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J4_OuIMErQQ"
      },
      "source": [
        "model = mlp_model(layers=layers,\n",
        "                      units=units,\n",
        "                      dropout_rate=dropout_rate,\n",
        "                      input_shape=x_train.shape[1:],\n",
        "                      num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrfbDmzFEUF_",
        "outputId": "31f75103-9e01-4335-8777-a54a65a07b14"
      },
      "source": [
        "loss = 'sparse_categorical_crossentropy'\n",
        "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "model.compile(optimizer='adam', loss=loss, metrics=['acc'])"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNB3w2zZEvHV"
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=2)]"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgMItysuGvL5",
        "outputId": "c60ab39d-cadf-4780-9277-d1dcec3d4383"
      },
      "source": [
        "x_val"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1254x20000 sparse matrix of type '<class 'numpy.float32'>'\n",
              "\twith 26467 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nIDbZrvXFcF1",
        "outputId": "9d9aeac9-20af-42db-e5f0-70a7fb042c3d"
      },
      "source": [
        "history = model.fit(\n",
        "            x_train,\n",
        "            train_labels,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks,\n",
        "            validation_data=(x_val, val_labels),\n",
        "            verbose=2,  # Logs once per epoch.\n",
        "            batch_size=batch_size)"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-196-3718bc3b86e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Logs once per epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             batch_size=batch_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 _r=1):\n\u001b[1;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:862 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:852 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:845 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:802 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:380 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:421 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:556 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1057 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:235 call\n        lambda: array_ops.identity(inputs))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/control_flow_util.py:110 smart_cond\n        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py:56 smart_cond\n        return true_fn()\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:232 dropped_inputs\n        rate=self.rate)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:549 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5229 dropout\n        return dropout_v2(x, rate, noise_shape=noise_shape, seed=seed, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5311 dropout_v2\n        x = ops.convert_to_tensor(x, name=\"x\")\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:346 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:272 constant\n        allow_broadcast=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:290 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse:1\", shape=(None,), dtype=float32), dense_shape=Tensor(\"stack:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUX8qf6DFfQ0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}